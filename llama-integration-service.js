/**
 * @file llama-integration-service.js
 * @description A standalone Node.js service that acts as a secure bridge between a local
 *              Llama AI installation and the nonprofit accounting PostgreSQL database.
 *
 * This service provides an API endpoint that accepts a natural language question,
 * constructs a detailed prompt with the database schema, sends it to a local Llama AI
 * model to generate a SQL query, validates the query for safety, executes it,
 * and returns the results.
 *
 * To Run:
 * 1. Ensure a local Llama AI model is running (e.g., via Ollama).
 * 2. Make sure PostgreSQL is running.
 * 3. Run `npm install express pg axios`.
 * 4. Run `node llama-integration-service.js`.
 * 5. Send POST requests to http://localhost:3001/api/llama-query with a JSON body like: { "query": "your question here" }
 */

const express = require('express');
const { Pool } = require('pg');
const axios = require('axios');

// --- CONFIGURATION ---
const PORT = process.env.LLAMA_SERVICE_PORT || 3001;
const LLAMA_API_ENDPOINT = process.env.LLAMA_API_ENDPOINT || 'http://localhost:11434/api/generate'; // Default for Ollama
const LLAMA_MODEL = process.env.LLAMA_MODEL || 'llama3'; // The model to use with Ollama

// Database connection configuration (should match your main app's config)
const dbConfig = {
    user: process.env.PGUSER || 'postgres',
    host: process.env.PGHOST || 'localhost',
    database: process.env.PGDATABASE || 'fund_accounting_db',
    password: process.env.PGPASSWORD || 'npfa123',
    port: process.env.PGPORT || 5432,
};

const pool = new Pool(dbConfig);
const app = express();
app.use(express.json());

// --- DATABASE SCHEMA INTROSPECTION ---

/**
 * Dynamically generates a detailed prompt describing the database schema.
 * This provides the necessary context for the LLM to write accurate queries.
 * @returns {Promise<string>} A detailed description of the database schema.
 */
async function getDatabaseSchemaPrompt() {
    console.log("Generating database schema prompt...");
    const client = await pool.connect();
    try {
        const tables = ['entities', 'funds', 'accounts', 'journal_entries', 'journal_entry_lines'];
        let schemaPrompt = 'Given the following PostgreSQL schema, please write a single, read-only SQL query to answer the user\'s question. Only return the SQL query and nothing else.\n\n';

        for (const table of tables) {
            schemaPrompt += `Table "${table}":\n`;
            const columnsResult = await client.query(`
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = $1 AND table_schema = 'public'
            `, [table]);
            
            columnsResult.rows.forEach(col => {
                schemaPrompt += `  - ${col.column_name} (${col.data_type})\n`;
            });
            schemaPrompt += '\n';
        }

        console.log("Schema prompt generated successfully.");
        return schemaPrompt;
    } catch (error) {
        console.error("Error generating schema prompt:", error);
        throw new Error("Could not generate database schema information.");
    } finally {
        client.release();
    }
}

// --- SECURITY VALIDATION ---

/**
 * Validates that the LLM-generated SQL is safe to execute.
 * This is a CRITICAL security function to prevent SQL injection and data modification.
 * @param {string} sql - The SQL query generated by the LLM.
 * @returns {boolean} True if the query is safe, otherwise throws an error.
 */
function isSafeQuery(sql) {
    if (!sql || typeof sql !== 'string') {
        throw new Error("Generated query is invalid or empty.");
    }

    const trimmedSql = sql.trim().toUpperCase();

    // 1. Must be a SELECT query
    if (!trimmedSql.startsWith('SELECT')) {
        throw new Error("Query is not a read-only SELECT statement.");
    }

    // 2. Blacklist dangerous keywords to prevent data modification or information leakage
    const forbiddenKeywords = [
        'INSERT', 'UPDATE', 'DELETE', 'DROP', 'TRUNCATE', 'ALTER', 'CREATE', 'GRANT', 'REVOKE',
        'EXECUTE', 'PREPARE', 'DEALLOCATE', 'SET', 'BEGIN', 'COMMIT', 'ROLLBACK', 'SAVEPOINT',
        '--', '/*', '*/', 'pg_sleep'
    ];

    for (const keyword of forbiddenKeywords) {
        if (trimmedSql.includes(keyword)) {
            throw new Error(`Query contains a forbidden keyword: ${keyword}.`);
        }
    }

    // 3. Prevent multiple statements
    if (trimmedSql.split(';').length > 2) { // Allow one trailing semicolon
        throw new Error("Query contains multiple statements, which is not allowed.");
    }

    console.log("SQL query passed all safety checks.");
    return true;
}


// --- LLM INTERACTION ---

/**
 * Sends a prompt to the local Llama AI model and returns the generated SQL.
 * @param {string} userQuery - The user's natural language question.
 * @returns {Promise<string>} The SQL query generated by the LLM.
 */
async function generateSqlFromLlama(userQuery) {
    const schemaPrompt = await getDatabaseSchemaPrompt();
    const fullPrompt = `${schemaPrompt}\nUser Question: "${userQuery}"\n\nSQL Query:`;

    console.log(`Sending prompt to Llama AI model '${LLAMA_MODEL}'...`);

    try {
        const response = await axios.post(LLAMA_API_ENDPOINT, {
            model: LLAMA_MODEL,
            prompt: fullPrompt,
            stream: false // We want the full response at once
        });

        // The response format from Ollama contains the generated text in `response.data.response`
        let generatedSql = response.data.response;

        // Clean up the response to get only the SQL
        // LLMs sometimes add backticks or explanations
        generatedSql = generatedSql.replace(/```sql/g, '').replace(/```/g, '').trim();
        
        console.log("Received SQL from Llama AI:", generatedSql);
        return generatedSql;
    } catch (error) {
        console.error("Error communicating with Llama AI API:", error.response ? error.response.data : error.message);
        throw new Error("Failed to get a response from the Llama AI service. Is it running?");
    }
}


// --- API ENDPOINT ---

/**
 * POST /api/llama-query
 * Accepts a natural language query, gets SQL from Llama, validates it,
 * executes it, and returns the results.
 */
app.post('/api/llama-query', async (req, res) => {
    const { query } = req.body;

    if (!query) {
        return res.status(400).json({ error: 'A "query" field is required in the request body.' });
    }

    try {
        // Step 1: Generate SQL from Llama AI
        const sqlQuery = await generateSqlFromLlama(query);

        // Step 2: Validate the generated SQL for security
        isSafeQuery(sqlQuery);

        // Step 3: Execute the safe SQL query
        console.log("Executing safe SQL query against the database...");
        const { rows } = await pool.query(sqlQuery);
        console.log(`Query executed successfully, returned ${rows.length} rows.`);

        // Step 4: Return the results
        res.status(200).json({
            originalQuery: query,
            executedSql: sqlQuery,
            results: rows
        });

    } catch (error) {
        console.error("Error in /api/llama-query endpoint:", error.message);
        res.status(500).json({
            error: "Failed to process your query.",
            details: error.message
        });
    }
});


// --- SERVER STARTUP ---
app.listen(PORT, () => {
    console.log(`Llama AI Integration Service is running on http://localhost:${PORT}`);
    console.log('Waiting for queries at /api/llama-query...');
});
